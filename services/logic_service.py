from qdrant_client import QdrantClient
from services.similarity_utils import encode_cached, warmup_embeddings
from rapidfuzz import process as rf_process, fuzz as rf_fuzz
import re
import logging
import inspect
from functools import lru_cache
from typing import Tuple, List, Dict, Any, Optional
from .redis_session_service import redis_session_manager
from core.exceptions.logic_exceptions import (
    MenuNotFoundException,
    OrderParsingException,
    PackagingNotFoundException,
)
from core.exceptions.session_exceptions import (
    SessionNotFoundException,
    InvalidSessionStepException,
    SessionUpdateFailedException
)
from .logic_order_utils import (
    validate_session,
    validate_and_create_order_item,
    validate_order_list,
    update_session_orders,
    format_order_list,
    create_order_response,
    calculate_similarity_score
)
# ì„¤ì • ìºì‹œ ë§¤ë‹ˆì € import
from config.config_cache import (
    get_compiled_separators_pattern,
    get_compiled_unit_pattern,
    get_compiled_number_pattern,
    get_temperature_keywords,
    get_korean_numbers,
    get_units_list,
    get_confirmation_keywords,
    get_packaging_keywords,
    get_similarity_thresholds,
    is_unit_required,
    get_default_temperature,
    get_menu_search_limit,
    get_vector_score_threshold
)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# Qdrant í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤
_client: Optional[QdrantClient] = None

def get_qdrant_client() -> QdrantClient:
    global _client
    if _client is None:
        _client = QdrantClient(url="http://localhost:6333")
    return _client

try:
    from qdrant_client.http.models import Filter, FieldCondition, MatchValue
except ImportError:
    from qdrant_client.models import Filter, FieldCondition, MatchValue

# ë©”ë‰´ ì°¾ê¸°
def search_menu(menu_item: str) -> Dict[str, Any]:
    try:
        # ì˜¨ë„ ê°ì§€ ë° ë©”ë‰´ëª… ì¶”ì¶œ
        cleaned_menu, user_temp, temp_detected = detect_temperature(menu_item)

        query_vector = list(encode_cached(cleaned_menu))
        client = get_qdrant_client()

        # Qdrant í´ë¼ì´ì–¸íŠ¸ API ë²„ì „ í˜¸í™˜ì„± ì²´í¬
        sig = inspect.signature(client.query_points)
        filter_kw = "filter" if "filter" in sig.parameters else (
            "query_filter" if "query_filter" in sig.parameters else None
        )

        try:
            from qdrant_client.http.models import Filter, FieldCondition, MatchValue
        except ImportError:
            from qdrant_client.models import Filter, FieldCondition, MatchValue

        # 2) ê³µí†µ ì¿¼ë¦¬ í•¨ìˆ˜ (temp í•„í„°ëŠ” ì˜µì…˜)
        def run_query(temp_filter: str | None):
            flt = None
            if temp_filter is not None:
                flt = Filter(must=[FieldCondition(key="temp", match=MatchValue(value=temp_filter))])

            # ë™ì ìœ¼ë¡œ ê²°ì •ëœ filter_kw ì‚¬ìš©
            kwargs = {
                "collection_name": "menu",
                "query": query_vector,
                "limit": get_menu_search_limit(),
                "score_threshold": get_vector_score_threshold(),
                "with_payload": True,
                "with_vectors": False,
            }
            
            if flt is not None and filter_kw is not None:
                kwargs[filter_kw] = flt # type: ignore
            
            return client.query_points(**kwargs)

        # 3) ì˜¨ë„ ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìì§€ì • > DBì˜¨ë„ > ê¸°ë³¸ê°’
        # ì‚¬ìš©ìê°€ ì˜¨ë„ë¥¼ ëª…ì‹œí–ˆë‹¤ë©´ í•´ë‹¹ ì˜¨ë„ë¡œë§Œ ê²€ìƒ‰, ì•„ë‹ˆë©´ ëª¨ë“  ì˜¨ë„ë¡œ ê²€ìƒ‰
        if temp_detected:
            # ì‚¬ìš©ìê°€ ì˜¨ë„ë¥¼ ëª…ì‹œí•œ ê²½ìš°: í•´ë‹¹ ì˜¨ë„ë¡œë§Œ ê²€ìƒ‰
            tried = [user_temp]
        else:
            # ì‚¬ìš©ìê°€ ì˜¨ë„ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì€ ê²½ìš°: ëª¨ë“  ì˜¨ë„ë¡œ ê²€ìƒ‰ (DB ì˜¨ë„ ìš°ì„ )
            tried = [None]  # í•„í„° ì—†ì´ ëª¨ë“  ë©”ë‰´ ê²€ìƒ‰
        
        enhanced_results = None

        for temp_try in tried:
            results = run_query(temp_try)
            if not results or not getattr(results, "points", None):
                continue

            enhanced = _process_menu_results(results, cleaned_menu)
            if enhanced:
                enhanced_results = enhanced
                break

        if not enhanced_results:
            raise MenuNotFoundException(menu_item)

        top = enhanced_results[0]

        thresholds = get_similarity_thresholds()

        if top[4] >= thresholds["menu_similarity_threshold"]:
            # ì˜¨ë„ ìš°ì„ ìˆœìœ„ ì ìš©: ì‚¬ìš©ìì§€ì • > DBì˜¨ë„ > ê¸°ë³¸ê°’
            final_temp = user_temp if temp_detected else top[3]  # DBì˜¨ë„ ì‚¬ìš©
            
            return {
                "menu_item": top[0],
                "price": top[1],
                "popular": top[2],
                "temp": final_temp,
            }

        else:
            raise MenuNotFoundException(menu_item)

    except MenuNotFoundException:
        raise

    except ConnectionError as e:
        logger.error(f"ë²¡í„° DB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise MenuNotFoundException(f"{menu_item} (ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì˜¤ë¥˜)")

    except Exception as e:
        logger.error(f"ë©”ë‰´ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise MenuNotFoundException(f"{menu_item} (ê²€ìƒ‰ ì˜¤ë¥˜)")

# ë©”ë‰´ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
def _process_menu_results(results, cleaned_menu: str) -> List[Tuple]:
    logger.info(f"ğŸ” Qdrant ì‘ë‹µ íƒ€ì…: {type(results)}")
    logger.info(f"ğŸ” Qdrant ì‘ë‹µ ë‚´ìš©: {results}")

    thresholds = get_similarity_thresholds()
    pop_bonus = thresholds["popular_bonus"]
    enhanced_results = []

    # ë°°ì¹˜ë¡œ ë©”ë‰´ëª… ì¶”ì¶œ
    menu_names = []
    valid_results = []

    for p in results.points:  # â† ì—¬ê¸°ë§Œ ìˆ˜ì •!
        payload = p.payload or {}
        menu_name = payload.get("menu_item")
        price = payload.get("price")
        if menu_name and price is not None:
            menu_names.append(menu_name)
            valid_results.append((menu_name, price, payload.get('popular', False), payload.get('temp', 'hot')))

    # ë°°ì¹˜ ì„ë² ë”© ì˜ˆì—´
    if menu_names:
        warmup_embeddings([cleaned_menu] + menu_names)

    # ìœ ì‚¬ë„ ê³„ì‚°
    for menu_name, price, popular, db_temp in valid_results:
        final_score, vector_score, best_fuzzy = calculate_similarity_score(cleaned_menu, menu_name)
        if popular:
            final_score += pop_bonus
        enhanced_results.append((menu_name, price, popular, db_temp, final_score, vector_score, best_fuzzy))

    enhanced_results.sort(key=lambda x: x[4], reverse=True)

    # ë¡œê¹… (ìƒìœ„ 3ê°œë§Œ)
    logger.info(f"'{cleaned_menu}' ê²€ìƒ‰ ê²°ê³¼:")
    for menu, price, popular, temp, final, _, _ in enhanced_results[:3]:
        logger.info(f"  - {menu}[{temp.upper()}]({price}ì›): ìµœì¢…={final:.3f}")

    return enhanced_results

# ìì—°ì–´ ìˆ˜ëŸ‰ íŒŒì‹± í•¨ìˆ˜
@lru_cache(maxsize=128)
def parse_quantity_from_text(text: str) -> int:
    text = text.strip().lower()

    # 1. ì•„ë¼ë¹„ì•„ ìˆ«ì ì¶”ì¶œ
    number_pattern = get_compiled_number_pattern()
    match = number_pattern.search(text)

    if match:
        return int(match.group())

    # 2. config íŒŒì¼ì˜ í•œê¸€ ìˆ«ì í™•ì¸
    korean_numbers = get_korean_numbers()

    for korean_word, value in korean_numbers.items():
        if korean_word in text:
            return value

    return 0

# ë©”ë‰´ì™€ ìˆ˜ëŸ‰ì„ í•¨ê»˜ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
def process_order(session_id: str, order_text: str) -> Dict[str, Any]:
    try:
        _ = validate_session(session_id, "started")

        # ì£¼ë¬¸ ë¶„ë¦¬
        individual_orders = split_multiple_orders(order_text)
        logger.info("ì£¼ë¬¸ ë¶„ë¦¬: %s", individual_orders)

        process_multiple_orders(session_id, individual_orders)

        updated_session = validate_session(session_id)
        orders = updated_session["data"]["orders"]

        message = f"ë‹¤ìŒ ì£¼ë¬¸ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤: {format_order_list(orders)}"

        return create_order_response(message, orders)

    except (MenuNotFoundException, OrderParsingException,
            SessionUpdateFailedException, InvalidSessionStepException, SessionNotFoundException):
        raise
    except Exception as e:
        logger.error(f"ì£¼ë¬¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise OrderParsingException("ì£¼ë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

# ì˜¨ë„ í‚¤ì›Œë“œ ë³µì›
def _restore_temperature_keywords(orders: List[str], replacements: Dict[str, str]) -> List[str]:
    restored_orders = []
    for order in orders:
        restored_order = order
        for placeholder, original in replacements.items():
            restored_order = restored_order.replace(placeholder, original)
        restored_orders.append(restored_order)
    return restored_orders

# ê°œë³„ ì£¼ë¬¸ìœ¼ë¡œ ë¶„ë¦¬
def split_multiple_orders(order_text: str) -> List[str]:
    cold_expressions, hot_expressions, temp_keywords_lower = get_temperature_keywords()

    # ì˜¨ë„ í‚¤ì›Œë“œë¥¼ ë²¡í„° ìœ ì‚¬ë„ë¡œ ë³´í˜¸
    protected_text = order_text
    words = order_text.split()
    replacements = {}

    thresholds = get_similarity_thresholds()
    rapidfuzz_threshold = thresholds["rapidfuzz_threshold"]

    for i, word in enumerate(words):
        cand = rf_process.extractOne(word.lower(), temp_keywords_lower, scorer=rf_fuzz.ratio)  # type: ignore
        if cand and cand[1] >= rapidfuzz_threshold:  # ì„ê³„ì¹˜(0~100)
            placeholder = f"__TEMP_{i}__"
            protected_text = protected_text.replace(word, placeholder)
            replacements[placeholder] = word


    # 1ë‹¨ê³„: configì˜ êµ¬ë¶„ìë¡œ ë¶„ë¦¬ ì‹œë„ (ëŒ€ë¹„ë¡œ ë’¤ì— ì˜ˆì‹œ ì¶”ê°€í•¨)
    separator_pattern = get_compiled_separators_pattern()
    orders = separator_pattern.split(protected_text)
    orders = [order.strip() for order in orders if order.strip()]

    # êµ¬ë¶„ìë¡œ ë¶„ë¦¬ë˜ì—ˆìœ¼ë©´ ë°˜í™˜
    if len(orders) > 1:
        return _restore_temperature_keywords(orders, replacements)

    # 2ë‹¨ê³„: íŒ¨í„´ ê¸°ë°˜ ìë™ ë¶„ë¦¬ (config ê¸°ë°˜)
    units = get_units_list()
    korean_numbers = get_korean_numbers()

    # ë™ì ìœ¼ë¡œ íŒ¨í„´ ìƒì„±
    unit_pattern = '|'.join(re.escape(unit) for unit in units)
    korean_nums = '|'.join(re.escape(num) for num in korean_numbers.keys())
    quantity_pattern = rf'(\d+|{korean_nums})'

    # ì „ì²´ íŒ¨í„´: ë©”ë‰´ëª… + ìˆ˜ëŸ‰ + ë‹¨ìœ„(ì„ íƒ)
    # ë‹¨ìœ„ê°€ ì—†ì–´ë„ ë™ì‘í•˜ë„ë¡ ìˆ˜ì •
    if is_unit_required():
        # ë‹¨ìœ„ í•„ìˆ˜
        full_pattern = rf'([ê°€-í£\s__TEMP_\d+__]*?[ê°€-í£]+[ê°€-í£\s__TEMP_\d+__]*?)\s*{quantity_pattern}\s*({unit_pattern})?'
    else:
        # ë‹¨ìœ„ ì„ íƒì 
        full_pattern = rf'([ê°€-í£\s__TEMP_\d+__]*?[ê°€-í£]+[ê°€-í£\s__TEMP_\d+__]*?)\s*{quantity_pattern}\s*({unit_pattern})?'

    matches = re.findall(full_pattern, order_text)

    if len(matches) > 1:
        # ì—¬ëŸ¬ ê°œ ë§¤ì¹˜ë˜ë©´ ê°ê°ì„ ì£¼ë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±
        parsed_orders = []
        for match in matches:
            if len(match) == 3:  # (ë©”ë‰´, ìˆ˜ëŸ‰, ë‹¨ìœ„)
                menu, qty, unit = match
                if unit:
                    parsed_orders.append(f"{menu.strip()} {qty} {unit}")
                else:
                    parsed_orders.append(f"{menu.strip()} {qty}")
            elif len(match) == 2:  # (ë©”ë‰´, ìˆ˜ëŸ‰)
                menu, qty = match
                parsed_orders.append(f"{menu.strip()} {qty}")

        restored_orders = _restore_temperature_keywords(parsed_orders, replacements)

        logger.info(f"íŒ¨í„´ ê¸°ë°˜ ë¶„ë¦¬: '{order_text}' â†’ {parsed_orders}")
        return restored_orders

    # ë¶„ë¦¬í•  ìˆ˜ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    return [order_text.strip()]

# ë‹¤ì¤‘ ì£¼ë¬¸ ì²˜ë¦¬
def process_multiple_orders(session_id: str, orders: List[str]) -> None:
    _ = validate_session(session_id)

    successful_orders = []
    failed_orders = []

    menu_texts = []
    order_data = []

    try:
        for order in orders:
            try:
                menu_text, quantity = parse_single_order_simplified(order)
                menu_texts.append(menu_text)
                order_data.append((order, menu_text, quantity))
            except Exception as e:
                # ê¸°íƒ€ ì˜ˆì™¸ë„ ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬
                logger.warning(f"ì£¼ë¬¸ '{order}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                failed_orders.append(f"'{order}': ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        if menu_texts:
            warmup_embeddings(menu_texts)

        # ê°œë³„ ì£¼ë¬¸ ì²˜ë¦¬
        for order, menu_text, quantity in order_data:
            try:
                validated_order = validate_and_create_order_item(menu_text, quantity, search_menu)

                # ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€ ë˜ëŠ” í•©ì¹˜ê¸°
                existing = None
                for existing_order in successful_orders:
                    if existing_order["menu_item"] == validated_order["menu_item"] and existing_order["temp"] == \
                            validated_order["temp"]:
                        existing = existing_order
                        break

                if existing:
                    existing["quantity"] += validated_order["quantity"]
                    existing["original"] += f", {validated_order['original']}"  # ì›ë³¸ ì£¼ë¬¸ í•©ì¹˜ê¸°
                else:
                    successful_orders.append(validated_order)

            except MenuNotFoundException:
                failed_orders.append(f"'{order}': ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            except Exception as e:
                logger.warning(f"ì£¼ë¬¸ '{order}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                failed_orders.append(f"'{order}': ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        validate_order_list(successful_orders)

        success = update_session_orders(session_id, successful_orders, "packaging")

        if not success:
            raise SessionUpdateFailedException(session_id, "í¬ì¥ ì •ë³´ ì—…ë°ì´íŠ¸")

    except Exception as e:
        logger.error(f"ë‹¤ì¤‘ ì£¼ë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise

# í…ìŠ¤íŠ¸ íŒŒì‹± ex) ì§œì¥ë©´ 2ê°œ -> (ì§œì¥ë©´, 2ê°œ)
def parse_single_order_simplified(order_text: str) -> Tuple[str, int]:

    # 1. ìˆ˜ëŸ‰ íŒŒì‹± (ì‹¤íŒ¨ì‹œ 0)
    quantity = parse_quantity_from_text(order_text)

    # 2. ë©”ë‰´ ì¶”ì¶œ (ìˆ˜ëŸ‰ ì œê±° í›„)
    menu_text = extract_menu_from_text(order_text, quantity)

    # ë©”ë‰´ê°€ ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
    if not menu_text:
        raise OrderParsingException(f"ë©”ë‰´ëª…ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{order_text}'. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.")

    return menu_text, quantity

# í…ìŠ¤íŠ¸ì—ì„œ ë©”ë‰´ ì¶”ì¶œ
def extract_menu_from_text(order_text: str, quantity: int) -> str:

    # 1. ì°¾ì€ ìˆ«ì íŒ¨í„´ ì œê±°
    text = re.sub(rf'{quantity}\s*\w*', '', order_text).strip()

    # 2. í•œê¸€ ìˆ«ìë„ ì œê±° (ìˆë‹¤ë©´)
    korean_numbers = get_korean_numbers()

    for korean_word, value in korean_numbers.items():
        if value == quantity:
            text = text.replace(korean_word, '').strip()
            break

    unit_pattern = get_compiled_unit_pattern()
    text = unit_pattern.sub('', text).strip()

    return text

# ì „ì²´ ì£¼ë¬¸ ê²€ì¦
def validate_single_order_simplified(order: str) -> Dict[str, Any]:
    if not order or not isinstance(order, str):
        raise OrderParsingException("ì£¼ë¬¸ í…ìŠ¤íŠ¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")

    # ë©”ë‰´ì™€ ìˆ˜ëŸ‰ íŒŒì‹±
    menu_text, quantity = parse_single_order_simplified(order)

    # ë©”ë‰´ ê²€ìƒ‰
    menu = search_menu(menu_text)

    # ìˆ˜ëŸ‰ì´ 0ì´ì–´ë„ í—ˆìš©, ìŒìˆ˜ëŠ” 0ìœ¼ë¡œ ë³´ì •
    if quantity < 0:
        quantity = 0

    return {
        "menu_item": menu["menu_item"],
        "price": menu["price"],
        "quantity": quantity,
        "original": order,
        "popular": menu["popular"],
        "temp": menu["temp"]
    }

@lru_cache(maxsize=16)
def search_packaging(packaging_text: str) -> str:
    packaging_keywords = get_packaging_keywords()
    if packaging_text in packaging_keywords:
        return packaging_keywords[packaging_text]
    else:
        raise PackagingNotFoundException(packaging_text)

def process_packaging(session_id: str, packaging_type: str) -> str:
    _ = validate_session(session_id, "packaging")

    packaging = search_packaging(packaging_type)

    # Redis ì„¸ì…˜ ì—…ë°ì´íŠ¸
    success = redis_session_manager.update_session(
        session_id,
        "packaging",
        {"packaging_type": packaging}
    )

    if not success:
        raise SessionUpdateFailedException(session_id, "í¬ì¥ ì •ë³´ ì—…ë°ì´íŠ¸")

    return f"{packaging}"

# í™•ì¸ ì‘ë‹µ ë¶„ì„ (ê¸ì •/ë¶€ì • íŒë‹¨)
@lru_cache(maxsize=64)
def analyze_confirmation(text: str) -> bool:
    text = text.strip().lower()

    positive_words, negative_words = get_confirmation_keywords()

    # ë¶€ì • ë¨¼ì € ì²´í¬ (ë” ëª…í™•í•œ ê±°ë¶€ ì˜ì‚¬)
    for word in negative_words:
        if word in text:
            return False

    # ê¸ì • ì²´í¬
    for word in positive_words:
        if word in text:
            return True

    # ê¸°ë³¸ê°’ì€ True (ê¸ì •ìœ¼ë¡œ ì²˜ë¦¬)
    return True

# ë²¡í„° + fuzzy ì¡°í•© ì˜¨ë„ ê°ì§€ (search_menuì™€ ë™ì¼í•œ ë°©ì‹)
@lru_cache(maxsize=256)
def detect_temperature(text: str) -> Tuple[str, str, bool]:
    logger.info(f"ğŸ” ì˜¨ë„ê°ì§€ ì…ë ¥: '{text}'")

    cold_expressions, hot_expressions, _ = get_temperature_keywords()
    thresholds = get_similarity_thresholds()

    # config ë¡œë“œ
    threshold = thresholds["temperature_threshold"]
    high_confidence_threshold = thresholds["temperature_high_confidence"]
    default_temp = get_default_temperature()

    # 1ë‹¨ê³„: ë‹¨ì–´ ë¶„ë¦¬
    text_lower = text.lower()
    all_expressions = cold_expressions + hot_expressions

    # 2ë‹¨ê³„: ê° ë‹¨ì–´ë¥¼ ì˜¨ë„ í‚¤ì›Œë“œì™€ ë¹„êµ
    best_temp = default_temp
    best_word = ""
    highest_score = 0.0
    temp_detected = False

    for word in all_expressions:
        if word in text_lower:
            final_score = 1.0  # í¬í•¨ë˜ë©´ 100% ë§¤ì¹­ìœ¼ë¡œ ì²˜ë¦¬

            if final_score > highest_score and final_score > threshold:
                highest_score = final_score
                best_word = word
                best_temp = "ice" if word in cold_expressions else "hot"
                temp_detected = True

    # 3ë‹¨ê³„: ê°ì§€ëœ ë‹¨ì–´ ì œê±°
    cleaned_text = text
    if best_word and highest_score > high_confidence_threshold:
        cleaned_text = text_lower.replace(best_word, "").strip()

    logger.info(f"ğŸ” ê°ì§€ê²°ê³¼ - ì˜¨ë„: {best_temp}, ì œê±°ë‹¨ì–´: '{best_word}', ì •ë¦¬ëœí…ìŠ¤íŠ¸: '{cleaned_text}', ê°ì§€ë¨: {temp_detected}")

    return cleaned_text, best_temp, temp_detected